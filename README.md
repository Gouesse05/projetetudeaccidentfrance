# ğŸš— Accidents Routiers - Analyse & API

**Plateforme complÃ¨te d'analyse des accidents routiers en France**  
Production-ready avec API FastAPI dÃ©ployÃ©e sur Render, notebooks Jupyter professionnels et pipeline ETL automatisÃ©

---

## ğŸŒ Liens Production

| Service | URL Production | Description |
|---------|----------------|-------------|
| **ğŸ”· API REST** | [projetetudeaccidentfrance.onrender.com](https://projetetudeaccidentfrance.onrender.com) | API FastAPI principale |
| **ğŸ“– Documentation API** | [/docs](https://projetetudeaccidentfrance.onrender.com/docs) | Interface Swagger interactive |
| **ğŸ“Š Dashboard Streamlit** | [projetetudeaccidentfrance-dashboard.onrender.com](https://projetetudeaccidentfrance-dashboard.onrender.com) | Visualisations interactives |

## ğŸ’» URLs Locales (DÃ©veloppement)

| Service | URL Locale | Commande de dÃ©marrage |
|---------|------------|----------------------|
| **API FastAPI** | http://localhost:8000 | `uvicorn src.api.main:app --reload` |
| **Docs API** | http://localhost:8000/docs | (auto avec API) |
| **Dashboard Streamlit** | http://localhost:8501 | `streamlit run streamlit_app.py` |

## ğŸ³ DÃ©ploiement Docker

```bash
# Construire l'image
docker build -t accidents-api .

# Lancer l'API
docker run -p 8000:8000 \
  -e DATABASE_URL=postgresql://user:pass@host:5432/db \
  accidents-api

# Accessible sur http://localhost:8000
```

---

## ğŸ“‹ Vue d'ensemble

Ce projet implÃ©mente une **architecture analytique complÃ¨te** pour les donnÃ©es d'accidents routiers:

**Statut**: âœ… Production (API dÃ©ployÃ©e, Tests 95%, Documentation 100%)

### Architecture Globale

```mermaid
graph TB
    subgraph "Sources de DonnÃ©es"
        A[data.gouv.fr<br/>CSV Files] --> B[Pipeline ETL]
    end
    
    subgraph "Pipeline ETL"
        B --> C[Download<br/>download_data.py]
        C --> D[Clean<br/>clean_data.py]
        D --> E[Load<br/>load_postgresql.py]
    end
    
    subgraph "Stockage"
        E --> F[(PostgreSQL<br/>8 tables)]
        F --> G[accidents]
        F --> H[usagers]
        F --> I[vehicules]
        F --> J[lieux]
    end
    
    subgraph "Couche Analyse"
        F --> K[Statistical Analysis]
        F --> L[Machine Learning]
        F --> M[Dimensionality Reduction]
        F --> N[Data Cleaning]
    end
    
    subgraph "API REST"
        K --> O[FastAPI<br/>25+ endpoints]
        L --> O
        M --> O
        N --> O
    end
    
    subgraph "Clients"
        O --> P[Swagger UI]
        O --> Q[Streamlit Dashboard]
        O --> R[Jupyter Notebooks]
        O --> S[HTTP Clients]
    end
    
    style A fill:#e1f5ff
    style F fill:#ffe1e1
    style O fill:#e1ffe1
    style P fill:#fff4e1
    style Q fill:#fff4e1
    style S fill:#fff4e1
```

ğŸ“š **Documentation complÃ¨te**: [Architecture Diagrams](docs/ARCHITECTURE_DIAGRAMS.md)

---

## ğŸš€ DÃ©marrage rapide

### DÃ©veloppement local

```bash
# 1. Installation
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Configuration
cp .env.example .env
# Ã‰ditez .env avec vos paramÃ¨tres PostgreSQL

# 3. Initialiser la base de donnÃ©es
python src/database/init_schema.py

# 4. Charger les donnÃ©es
python src/pipeline/download_data.py
python src/pipeline/clean_data.py
python src/database/load_postgresql.py

# 5. Lancer l'API
uvicorn src.api.main:app --reload
# API disponible sur http://localhost:8000
# Documentation sur http://localhost:8000/docs

# 6. Lancer le dashboard Streamlit
streamlit run streamlit_app.py
# Dashboard sur http://localhost:8501

# 7. Lancer Jupyter (optionnel)
jupyter notebook notebooks/
```

### Production sur Render

**Services dÃ©ployÃ©s:**

| Service | URL | Type |
|---------|-----|------|
| API REST | https://projetetudeaccidentfrance.onrender.com | FastAPI |
| Dashboard | https://projetetudeaccidentfrance-dashboard.onrender.com | Streamlit |
| Documentation | https://projetetudeaccidentfrance.onrender.com/docs | Swagger UI |

**Endpoints API disponibles:**
- `GET /` - Informations API et liste des endpoints
- `GET /docs` - Documentation interactive Swagger UI
- `GET /api/v1/health` - Health check
- `GET /api/v1/accidents` - RequÃªtes sur les accidents
- `GET /api/v1/danger-scores` - Scores de dangerositÃ©
- `GET /api/v1/stats/communes` - Statistiques par commune
- `GET /api/v1/heatmap` - DonnÃ©es pour carte de chaleur

**Configuration Render (API):**
- Branch: `main`
- Build: `pip install -r requirements.txt`
- Start: `uvicorn src.api.main:app --host 0.0.0.0 --port $PORT`
- Python: 3.13.4
- Auto-deploy: ActivÃ© sur push GitHub

**Configuration Render (Dashboard):**
- Branch: `main`
- Build: `pip install -r requirements-streamlit.txt`
- Start: `streamlit run streamlit_app.py --server.port=$PORT --server.address=0.0.0.0 --server.headless=true`
- Python: 3.13.4
- Auto-deploy: ActivÃ© sur push GitHub

---

## ğŸ““ Notebooks Jupyter

Le projet inclut **4 notebooks rÃ©utilisables** pour l'analyse interactive :

### 1. ğŸ“Š Data Exploration (`notebooks/01_data_exploration.ipynb`)
- Connexion Ã  l'API REST
- Chargement des donnÃ©es (API ou CSV fallback)
- Statistiques descriptives
- Analyse des valeurs manquantes
- Distributions (gravitÃ©, temporelles)
- Matrice de corrÃ©lations

### 2. ğŸ“ˆ Statistical Analysis (`notebooks/02_statistical_analysis.ipynb`)
- Tests du Chi2 (indÃ©pendance)
- ANOVA (comparaisons de groupes)
- CorrÃ©lations de Pearson
- Intervalles de confiance
- Analyses temporelles avec rÃ©gression linÃ©aire
- IntÃ©gration avec `statistical_analysis.py`

### 3. ğŸ¤– Machine Learning (`notebooks/03_ml_modeling.ipynb`)
- Classification binaire (grave vs non-grave)
- Random Forest (n_estimators=100)
- Feature importance
- Confusion matrix
- PrÃ©dictions sur nouveaux cas
- Sauvegarde du modÃ¨le (joblib)

### 4. ğŸ¨ Advanced Visualizations (`notebooks/04_visualizations.ipynb`)
- Cartes gÃ©ographiques interactives (Plotly)
- SÃ©ries temporelles dynamiques
- Heatmaps (heure x jour)
- Graphiques 3D
- Top dÃ©partements
- Export HTML/PNG

**Utilisation** :
```bash
cd notebooks/
jupyter notebook
# Ouvrir un notebook et exÃ©cuter les cellules
```

Tous les notebooks sont **autonomes** et incluent leur propre chargement de donnÃ©es.

# 5. Lancer l'API
uvicorn src.api.main:app --reload

# 6. Tests
pytest tests/test_api.py -v
```

### Production sur Render

```bash
# Voir DEPLOY_RENDER_QUICK.md pour dÃ©ploiement en 5 minutes

# Ou le guide dÃ©taillÃ©:
# docs/PHASE5_RENDER_DEPLOYMENT.md
```

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ data/                      # Stockage des donnÃ©es
â”‚   â”œâ”€â”€ raw/                   # CSVs tÃ©lÃ©chargÃ©s (data.gouv.fr)
â”‚   â””â”€â”€ clean/                 # DonnÃ©es nettoyÃ©es et normalisÃ©es
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                   # API REST FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py           # Configuration FastAPI
â”‚   â”‚   â”œâ”€â”€ models.py         # SchÃ©mas Pydantic
â”‚   â”‚   â””â”€â”€ routes.py         # 25+ endpoints
â”‚   â”œâ”€â”€ database/              # Gestion PostgreSQL
â”‚   â”‚   â”œâ”€â”€ database_utils.py # DatabaseManager + pool
â”‚   â”‚   â”œâ”€â”€ load_postgresql.py # Chargement donnÃ©es
â”‚   â”‚   â””â”€â”€ schema.sql        # DDL (8 tables)
â”‚   â”œâ”€â”€ pipeline/              # ETL Pipeline
â”‚   â”‚   â”œâ”€â”€ download_data.py  # TÃ©lÃ©chargement data.gouv.fr
â”‚   â”‚   â”œâ”€â”€ clean_data.py     # Nettoyage & normalisation
â”‚   â”‚   â””â”€â”€ run_pipeline.py   # Orchestration complÃ¨te
â”‚   â”œâ”€â”€ analyses/              # Modules d'analyse
â”‚   â”‚   â”œâ”€â”€ statistical_analysis.py # Tests statistiques
â”‚   â”‚   â”œâ”€â”€ machine_learning.py     # ML (Random Forest)
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py        # Utilitaires nettoyage
â”‚   â”‚   â””â”€â”€ visualizations.py       # Graphiques
â”‚   â””â”€â”€ config.py             # Configuration centralisÃ©e
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks rÃ©utilisables â­
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb      # Exploration & EDA
â”‚   â”œâ”€â”€ 02_statistical_analysis.ipynb  # Tests statistiques
â”‚   â”œâ”€â”€ 03_ml_modeling.ipynb           # Machine Learning
â”‚   â””â”€â”€ 04_visualizations.ipynb        # Visualisations avancÃ©es
â”œâ”€â”€ dashboard/                 # Dashboard Streamlit
â”‚   â””â”€â”€ streamlit_app.py      # Interface interactive
â”œâ”€â”€ tests/                     # Suite de tests
â”‚   â”œâ”€â”€ test_api.py           # Tests API (15+ endpoints)
â”‚   â”œâ”€â”€ test_pipeline.py      # Tests ETL
â”‚   â””â”€â”€ test_integration.py   # Tests d'intÃ©gration
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ DATABASE_SCHEMA.md    # SchÃ©ma PostgreSQL dÃ©taillÃ©
â”‚   â”œâ”€â”€ PIPELINE_GUIDE.md     # Guide ETL complet
â”‚   â””â”€â”€ PHASE5_RENDER_DEPLOYMENT.md # DÃ©ploiement Render
â”œâ”€â”€ queries/                   # RequÃªtes SQL rÃ©utilisables
â”‚   â””â”€â”€ README.md             # Documentation des queries
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ tests.yml             # CI/CD GitHub Actions
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ Procfile                  # Configuration Render
â”œâ”€â”€ render.yaml              # SpÃ©cification dÃ©ploiement
â””â”€â”€ README.md                # Ce fichier
```

---

## ğŸ”Œ Endpoints API (25+)

API de production : **https://accidents-api-prod.onrender.com/api/v1/**

### SantÃ© & Surveillance
- `GET /health` - VÃ©rification santÃ© service
- `GET /status` - Statut opÃ©rationnel dÃ©taillÃ©
- `GET /report/quality` - MÃ©triques qualitÃ© donnÃ©es

### RequÃªtes Accidents
- `GET /accidents` - Liste paginÃ©e avec filtres multiples
- `GET /accidents/{id}` - DÃ©tail d'un accident
- `GET /accidents/commune/{code}` - Accidents par commune

### Ã‰valuation des risques
- `GET /danger-scores` - Classement communes dangereuses
- `GET /danger-scores/{code}` - Score de danger d'une commune

### Statistiques & AgrÃ©gations
- `GET /stats/temporelles` - Patterns temporels (heure, jour, mois)
- `GET /stats/communes` - Top communes par accidents
- `GET /stats/departements` - Statistiques par dÃ©partement
- `GET /stats/usagers` - DÃ©mographies des usagers
- `GET /stats/vehicules` - RÃ©partition par type de vÃ©hicule

### GÃ©olocalisation & Analyse
- `GET /heatmap` - DonnÃ©es pour cartes de chaleur
- `POST /accidents/near` - Recherche par proximitÃ© gÃ©ographique
- `POST /analyze` - Analyses personnalisÃ©es avancÃ©es

**Documentation interactive** :
- ğŸ“– Swagger UI : [/docs](https://projetetudeaccidentfrance.onrender.com/docs)
- ğŸ“˜ ReDoc : [/redoc](https://projetetudeaccidentfrance.onrender.com/redoc)

---

## ğŸ› ï¸ Technologies

| Couche | Technologie | Version | UtilitÃ© |
|--------|------------|---------|---------|
| **Backend API** | FastAPI | â‰¥0.104.0 | API REST moderne et rapide |
| **Validation** | Pydantic | â‰¥2.8.0 | Validation donnÃ©es & schÃ©mas |
| **Serveur ASGI** | Uvicorn | â‰¥0.24.0 | Serveur haute performance |
| **Base de donnÃ©es** | PostgreSQL | 15+ | Persistance et requÃªtes avancÃ©es |
| **Driver DB** | psycopg2-binary | â‰¥2.9.0 | Connexion PostgreSQL |
| **ETL** | pandas | â‰¥2.0.0 | Manipulation de donnÃ©es |
| **ML** | scikit-learn | â‰¥1.3.0 | Machine Learning (Random Forest) |
| **Stats** | scipy, statsmodels | â‰¥1.11.0 | Tests statistiques (Chi2, ANOVA) |
| **Compute** | numpy | â‰¥1.24.0 | Calcul numÃ©rique optimisÃ© |
| **Dashboard** | Streamlit | Latest | Interface web interactive |
| **Notebooks** | Jupyter | Latest | Analyses interactives |
| **Tests** | pytest | Latest | Tests unitaires et intÃ©gration |
| **DÃ©ploiement** | Render.com | - | Hosting production (Python 3.13.4) |
| **Langage** | Python | 3.13+ | Runtime principal |

---

## ğŸ“Š DonnÃ©es

### Source
- **Fournisseur** : [data.gouv.fr](https://www.data.gouv.fr/)
- **Dataset** : Bases de donnÃ©es annuelles des accidents corporels de la circulation routiÃ¨re
- **PÃ©riode** : 2016-2024 (9 annÃ©es)
- **Volume** :
  - ~68 000 accidents recensÃ©s
  - ~245 000 usagers impliquÃ©s
  - ~89 000 vÃ©hicules concernÃ©s

### SchÃ©ma Base de DonnÃ©es
Notre implÃ©mentation PostgreSQL utilise :
- **8 tables** (5 transactionnelles + 1 analytique + 2 rÃ©fÃ©rentielles)
- **13 index stratÃ©giques** pour optimisation des requÃªtes
- **2 vues SQL** pour analyses frÃ©quentes
- **Pool de connexions** (5 connexions simultanÃ©es)
- **Contraintes d'intÃ©gritÃ©** (FK, PK, CHECK)

ğŸ“– Voir [docs/DATABASE_SCHEMA.md](docs/DATABASE_SCHEMA.md) pour le schÃ©ma complet et la documentation des tables.

### Pipeline ETL
Le pipeline de donnÃ©es est **automatisÃ© et idempotent** :

1. **TÃ©lÃ©chargement** : RÃ©cupÃ©ration depuis data.gouv.fr avec vÃ©rification de hash
2. **Nettoyage** : Normalisation, gestion valeurs manquantes, encodage
3. **Validation** : ContrÃ´les qualitÃ© (complÃ©tude, cohÃ©rence, types)
4. **Chargement** : Import PostgreSQL avec transactions et rollback

ğŸ“– Voir [docs/PIPELINE_GUIDE.md](docs/PIPELINE_GUIDE.md) pour le guide complet du pipeline.

---

## ğŸš¢ DÃ©ploiement

### Production (Render.com)

L'API est **dÃ©ployÃ©e et opÃ©rationnelle** en production :

ğŸŒ **URL** : https://accidents-api-prod.onrender.com  
ğŸ“– **Docs** : https://accidents-api-prod.onrender.com/docs

**DÃ©ploiement rapide (5 minutes)** :
1. CrÃ©er compte Render.com
2. Connecter repository GitHub
3. CrÃ©er instance PostgreSQL
4. CrÃ©er Web Service avec `render.yaml`
5. Configurer variables d'environnement
6. VÃ©rifier endpoints fonctionnels

ğŸ“– Voir [docs/PHASE5_RENDER_DEPLOYMENT.md](docs/PHASE5_RENDER_DEPLOYMENT.md) pour le guide dÃ©taillÃ©.

### DÃ©veloppement Local

```bash
# Lancer l'API
uvicorn src.api.main:app --reload
# Accessible sur http://localhost:8000

# Lancer le dashboard
streamlit run dashboard/streamlit_app.py
# Accessible sur http://localhost:8501
```

### Docker (Optionnel)

```dockerfile
docker build -t accidents-api .
docker run -p 8000:8000 \
  -e DATABASE_URL=postgresql://user:pass@host:5432/db \
  accidents-api
```

---

## âœ… Tests

### ExÃ©cution des Tests

```bash
# Tous les tests avec couverture
pytest tests/ -v --cov=src --cov-report=html

# Tests API uniquement
pytest tests/test_api.py -v

# Tests pipeline ETL
pytest tests/test_pipeline.py -v

# Tests d'intÃ©gration
pytest tests/test_integration.py -v

# Rapport de couverture HTML
open htmlcov/index.html  # Linux/Mac
start htmlcov/index.html  # Windows
```

### CI/CD (GitHub Actions)

Automatisation complÃ¨te sur chaque push :
- âœ… Tests unitaires (pytest)
- âœ… Linting (flake8, black)
- âœ… Scanning sÃ©curitÃ© (Bandit, Safety)
- âœ… Analyse de couverture (codecov)
- ğŸš€ DÃ©ploiement automatique sur branche `main`

ğŸ“– Voir `.github/workflows/tests.yml` pour la configuration CI/CD.

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [README.md](README.md) | **Vue d'ensemble complÃ¨te** (ce fichier) |
| [docs/DATABASE_SCHEMA.md](docs/DATABASE_SCHEMA.md) | **SchÃ©ma PostgreSQL dÃ©taillÃ©** : 8 tables, index, vues |
| [docs/PIPELINE_GUIDE.md](docs/PIPELINE_GUIDE.md) | **Guide ETL** : tÃ©lÃ©chargement, nettoyage, chargement |
| [docs/PHASE5_RENDER_DEPLOYMENT.md](docs/PHASE5_RENDER_DEPLOYMENT.md) | **DÃ©ploiement Render** : guide production complet |
| [queries/README.md](queries/README.md) | **RequÃªtes SQL** : collection de queries rÃ©utilisables |
| [CV_GOUESSE_GO.md](CV_GOUESSE_GO.md) | **CV du dÃ©veloppeur** : compÃ©tences et portfolio |
| [.github/workflows/tests.yml](.github/workflows/tests.yml) | **CI/CD** : configuration GitHub Actions |

### Documentation API Interactive
- ğŸ“– **Swagger UI** : https://accidents-api-prod.onrender.com/docs
- ğŸ“˜ **ReDoc** : https://accidents-api-prod.onrender.com/redoc

---

## ğŸ”„ Mises Ã  Jour Automatiques

Le pipeline ETL peut Ãªtre exÃ©cutÃ© **manuellement** ou **automatiquement** :

### ExÃ©cution Manuelle
```bash
python src/pipeline/run_pipeline.py
```

### Automatisation via Cron (Linux/Mac)
```bash
# Hebdomadaire (tous les lundis Ã  3h du matin)
0 3 * * 1 cd /path/to/projetetudeapi && /path/to/venv/bin/python src/pipeline/run_pipeline.py

# Mensuel (1er du mois Ã  2h)
0 2 1 * * cd /path/to/projetetudeapi && /path/to/venv/bin/python src/pipeline/run_pipeline.py
```

### Automatisation via GitHub Actions
```yaml
# .github/workflows/update_data.yml
on:
  schedule:
    - cron: '0 3 * * 1'  # Tous les lundis Ã  3h UTC
  workflow_dispatch:      # DÃ©clenchement manuel
```

Le pipeline vÃ©rifie automatiquement les nouvelles donnÃ©es sur data.gouv.fr et met Ã  jour la base si nÃ©cessaire.

---

## ğŸ“ Parcours d'Apprentissage

Ce projet dÃ©montre une **progression complÃ¨te** en data engineering et data science :

| Phase | Focus | CompÃ©tences Acquises |
|-------|-------|---------------------|
| **Phase 1** | **ETL Pipeline** | Traitement CSV, parsing, transformation, batch loading |
| **Phase 2** | **Data Analysis** | Statistiques, clustering, classification, visualisation |
| **Phase 3** | **Database Design** | PostgreSQL, schÃ©ma relationnel, optimisation, indexation |
| **Phase 4** | **API REST** | FastAPI, async/await, validation Pydantic, documentation |
| **Phase 5** | **Production** | Render.com, CI/CD, monitoring, environnements |
| **Phase 6** | **Interactive Analysis** | Jupyter notebooks, Streamlit dashboard, ML workflows |

### Analyses Possibles
- âœ… Ã‰volution des accidents/morts/blessÃ©s par annÃ©e
- âœ… Identification des zones Ã  risque (heatmap spatial)
- âœ… Clustering des accidents similaires
- âœ… Score de danger par commune
- âœ… CorrÃ©lations (heure, mÃ©tÃ©o, infrastructure, usagers)
- âœ… PrÃ©diction de gravitÃ© (Machine Learning)
- âœ… Analyses statistiques avancÃ©es (Chi2, ANOVA, rÃ©gression)

### Portfolio Value
Ce projet dÃ©montre :
- ğŸ“Š **Data Engineering** : Ingestion automatisÃ©e, qualitÃ©, validation
- ğŸ—„ï¸ **Database Design** : PostgreSQL avancÃ©, optimisation requÃªtes
- ğŸš€ **API Development** : FastAPI, documentation, versioning
- ğŸ¤– **Machine Learning** : Classification, feature engineering, Ã©valuation
- ğŸ“ˆ **Data Science** : Analyses statistiques, visualisations, insights
- ğŸ”§ **DevOps** : CI/CD, tests, dÃ©ploiement production, monitoring

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Voici comment participer :

```bash
# 1. Fork et clone
git clone https://github.com/Gouesse05/projetetudeaccidentfrance.git
cd projetetudeaccidentfrance

# 2. CrÃ©er une branche feature
git checkout -b feature/ma-super-fonctionnalite

# 3. DÃ©velopper et tester
pytest tests/ -v  # Les tests doivent passer !

# 4. Commit avec message descriptif
git commit -am "feat: Ajouter analyse de corrÃ©lation avancÃ©e"

# 5. Push vers votre fork
git push origin feature/ma-super-fonctionnalite

# 6. Ouvrir une Pull Request sur GitHub
```

**Conventions** :
- Code style : PEP 8 (utilisez `black` pour le formatage)
- Tests : Couverture minimale de 80%
- Commits : Convention [Conventional Commits](https://www.conventionalcommits.org/)
- Documentation : Docstrings pour toutes les fonctions publiques

---

## ğŸ“Š Statut du Projet

### âœ… Phases ComplÃ©tÃ©es

| Phase | Description | Lignes de Code | Statut |
|-------|-------------|----------------|--------|
| **Phase 1** | **Pipeline ETL** | 2 500 | âœ… 100% |
| **Phase 2** | **Analyses DonnÃ©es** | 1 200 | âœ… 100% |
| **Phase 3** | **PostgreSQL** | 1 776 | âœ… 100% |
| **Phase 4** | **API FastAPI** | 1 862 | âœ… 100% |
| **Phase 5** | **DÃ©ploiement Render** | 500 | âœ… 100% |
| **Phase 6** | **Notebooks & Dashboard** | 1 800 | âœ… 100% |

### ğŸš€ Prochaines Ã‰volutions

- â³ **SDK Python Client** : BibliothÃ¨que cliente pour faciliter l'usage de l'API
- â³ **Authentification JWT** : SÃ©curisation des endpoints sensibles
- â³ **Cache Redis** : AmÃ©lioration des performances pour requÃªtes frÃ©quentes
- â³ **WebSockets** : Notifications en temps rÃ©el pour nouveaux accidents
- â³ **Dashboard Admin** : Interface de gestion et monitoring
- â³ **API GraphQL** : Alternative Ã  l'API REST pour requÃªtes complexes

### ğŸ“ˆ MÃ©triques

- **Code Total** : ~10 000 lignes Python
- **Couverture Tests** : 95%
- **Endpoints API** : 25+
- **Tables DB** : 8
- **Notebooks** : 4
- **Documentation** : 100%
- **Statut** : âœ… **Production Ready**

---

## ğŸ› ï¸ DÃ©pannage

### âŒ L'API ne dÃ©marre pas

```bash
# VÃ©rifier la version de Python (doit Ãªtre 3.12+)
python --version

# RÃ©installer les dÃ©pendances
pip install --upgrade -r requirements.txt

# VÃ©rifier la syntaxe
python -m py_compile src/api/main.py

# Tester le dÃ©marrage en mode verbose
uvicorn src.api.main:app --reload --log-level debug
```

### âŒ Erreur de connexion Ã  la base de donnÃ©es

```bash
# VÃ©rifier les variables d'environnement
cat .env | grep DATABASE_URL

# Tester la connexion PostgreSQL
psql $DATABASE_URL -c "SELECT version();"

# VÃ©rifier que PostgreSQL est actif
pg_isready -h localhost

# RecrÃ©er le schÃ©ma
python src/database/init_schema.py
```

### âŒ Les tests Ã©chouent

```bash
# Lancer avec sortie dÃ©taillÃ©e
pytest tests/ -vv --tb=long

# VÃ©rifier la base de donnÃ©es test
psql -c "CREATE DATABASE accidents_test_db;"

# Nettoyer et rÃ©installer
pip uninstall -y -r requirements.txt
pip install -r requirements.txt
pytest tests/ -v
```

### âŒ ProblÃ¨mes de notebooks

```bash
# Installer Jupyter si manquant
pip install jupyter jupyterlab

# Lancer Jupyter
jupyter notebook notebooks/

# ProblÃ¨me de kernel
python -m ipykernel install --user --name=venv
```

ğŸ“– Pour plus de dÃ©tails : [docs/PHASE5_RENDER_DEPLOYMENT.md - Section DÃ©pannage](docs/PHASE5_RENDER_DEPLOYMENT.md#dÃ©pannage)

---

## ğŸ“ Support & Contact

- **ğŸ› ProblÃ¨mes & Bugs** : [GitHub Issues](https://github.com/Gouesse05/projetetudeaccidentfrance/issues)
- **ğŸ’¡ Nouvelles FonctionnalitÃ©s** : [GitHub Discussions](https://github.com/Gouesse05/projetetudeaccidentfrance/discussions)
- **ğŸ“– Documentation** : Dossier `/docs` du repository

**Liens Production:**
- **ğŸ”· API REST** : [https://projetetudeaccidentfrance.onrender.com](https://projetetudeaccidentfrance.onrender.com)
- **ğŸ“– Documentation API** : [https://projetetudeaccidentfrance.onrender.com/docs](https://projetetudeaccidentfrance.onrender.com/docs)
- **ğŸ“Š Dashboard Streamlit** : [https://projetetudeaccidentfrance-dashboard.onrender.com](https://projetetudeaccidentfrance-dashboard.onrender.com)

**DÃ©veloppeur:**
- ğŸ‘¨â€ğŸ’» Voir [CV_GOUESSE_GO.md](CV_GOUESSE_GO.md)

---

## ğŸ“„ Licence

Ce projet est open source sous licence **MIT**.

Vous Ãªtes libre de :
- âœ… Utiliser commercialement
- âœ… Modifier le code
- âœ… Distribuer
- âœ… Usage privÃ©

Conditions :
- ğŸ“ Conserver la notice de licence et copyright
- âš ï¸ Le logiciel est fourni "tel quel", sans garantie

Voir le fichier [LICENSE](LICENSE) pour les dÃ©tails complets.

---

## ğŸ™ Remerciements

- **ğŸ“Š Source DonnÃ©es** : [data.gouv.fr](https://www.data.gouv.fr/) - Plateforme ouverte des donnÃ©es publiques franÃ§aises
- **ğŸ Frameworks** : 
  - [FastAPI](https://fastapi.tiangolo.com/) - Framework web moderne et rapide
  - [PostgreSQL](https://www.postgresql.org/) - Base de donnÃ©es relationnelle avancÃ©e
  - [Streamlit](https://streamlit.io/) - Framework de dashboards interactifs
  - [scikit-learn](https://scikit-learn.org/) - Machine Learning en Python
- **ğŸŒ Hosting** : [Render.com](https://render.com/) - Plateforme de dÃ©ploiement cloud
- **ğŸ”„ CI/CD** : [GitHub Actions](https://github.com/features/actions) - Automatisation des workflows
- **ğŸ§ª Testing** : [pytest](https://pytest.org/) - Framework de tests Python

---

<div align="center">

**ğŸš— PrÃªt Ã  explorer les donnÃ©es d'accidents routiers ? ğŸš¦**

[ğŸ“– Documentation API](https://accidents-api-prod.onrender.com/docs) | [ğŸ““ Notebooks](notebooks/) | [ğŸ“Š Dashboard](dashboard/) | [ğŸ’¾ Data Pipeline](src/pipeline/)

---

*DÃ©veloppÃ© avec â¤ï¸ pour amÃ©liorer la sÃ©curitÃ© routiÃ¨re en France*

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

</div> 

