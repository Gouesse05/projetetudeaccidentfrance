# ðŸ“Š Phase 3: SchÃ©ma PostgreSQL et Chargement des DonnÃ©es

## Vue d'ensemble

Phase 3 implÃ©mente la **couche persistence** du projet avec :
- âœ… SchÃ©ma PostgreSQL complet (5 tables + rÃ©fÃ©rentiels)
- âœ… Scripts de chargement avec validation
- âœ… RequÃªtes d'analyse prÃ©-compilÃ©es
- âœ… Cache analytique (scores de danger)
- âœ… Vues pour faciliter les analyses

**Objectif**: Transformer les CSV nettoyÃ©s â†’ Base de donnÃ©es relationnelle optimisÃ©e pour les analyses d'assurance.

---

## ðŸ“ Architecture du SchÃ©ma

### Tables Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SCHÃ‰MA POSTGRESQL                     â”‚
â”‚         accidents_schema (publique, 8 tables)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RÃ‰FÃ‰RENTIELS:
â”œâ”€â”€ departements      (rÃ©fÃ©renciel + donnÃ©es INSEE)
â”œâ”€â”€ communes          (gÃ©olocalisation + densitÃ©)

DONNÃ‰ES TRANSACTIONNELLES:
â”œâ”€â”€ accidents         (table principale, ~60k-80k rows)
â”œâ”€â”€ caracteristiques  (conditions de l'accident)
â”œâ”€â”€ lieux            (gÃ©olocalisation prÃ©cise)
â”œâ”€â”€ usagers          (donnÃ©es des personnes impliquÃ©es)
â””â”€â”€ vehicules        (donnÃ©es des vÃ©hicules)

ANALYTIQUE:
â””â”€â”€ score_danger_commune (cache de scores composites)

VUES:
â”œâ”€â”€ v_accidents_enrichis (join de toutes les tables)
â””â”€â”€ v_resume_communes    (agrÃ©gations par commune)
```

### Diagramme Relationnel

```
departements (code_dept PK)
    â†“ (id_dept FK)
communes (code_com PK) â”€â”€â”
    â†“ (id_com FK)        â”‚
accidents (num_acc PK) â†â”€â”˜
    â†“ (id_accident FK)
    â”œâ”€â”€ caracteristiques
    â”œâ”€â”€ lieux
    â”œâ”€â”€ usagers
    â””â”€â”€ vehicules
    
score_danger_commune
    â†“ (id_com FK)
communes
```

### DÃ©tails des Tables

#### 1. **departements** (RÃ©fÃ©rentiel)
```sql
CREATE TABLE departements (
    id_dept SERIAL PRIMARY KEY,
    code_dept VARCHAR(5) UNIQUE NOT NULL,        -- '75', '92', '13', ...
    nom_dept VARCHAR(100) NOT NULL,              -- 'Paris', 'Bouches-du-RhÃ´ne', ...
    region VARCHAR(100),                         -- 'ÃŽle-de-France', 'PACA', ...
    population BIGINT,                           -- DonnÃ©es INSEE
    surface_km2 DECIMAL(10, 2),
    densite_hab_km2 DECIMAL(10, 2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- code_dept (UNIQUE)
```

#### 2. **communes** (RÃ©fÃ©rentiel + Localisation)
```sql
CREATE TABLE communes (
    id_com SERIAL PRIMARY KEY,
    code_com VARCHAR(10) UNIQUE NOT NULL,        -- Code INSEE commune
    nom_com VARCHAR(100) NOT NULL,
    id_dept INTEGER FK REFERENCES departements,
    population BIGINT,
    densite_hab_km2 DECIMAL(10, 2),
    latitude DECIMAL(10, 8),                     -- CoordonnÃ©es centre commune
    longitude DECIMAL(10, 8),
    zone_urbaine BOOLEAN,                        -- TRUE si densitÃ© > 100/kmÂ²
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- idx_communes_dept (id_dept)
- idx_communes_code (code_com) - pour jointures rapides

CLÃ‰ Ã‰TRANGÃˆRE:
- id_dept â†’ departements.id_dept (CASCADE)
```

#### 3. **accidents** (Table Principale)
```sql
CREATE TABLE accidents (
    id_accident SERIAL PRIMARY KEY,
    num_acc VARCHAR(20) UNIQUE NOT NULL,         -- ClÃ© mÃ©tier
    
    -- Date/Temps (INDEXÃ‰E pour analyses temporelles)
    date_accident DATE NOT NULL,
    annee INTEGER NOT NULL,                      -- â­ IndexÃ©
    mois INTEGER CHECK (1-12),
    jour_mois INTEGER CHECK (1-31),
    jour_semaine INTEGER CHECK (1-7),            -- 1=Lundi, 7=Dimanche
    heure INTEGER CHECK (0-23),                  -- â­ IndexÃ©
    minute INTEGER CHECK (0-59),
    
    -- Localisation (INDEXÃ‰E)
    id_com INTEGER FK REFERENCES communes,      -- â­ IndexÃ©
    
    -- CaractÃ©ristiques
    nombre_vehicules INTEGER CHECK (>0),
    nombre_personnes INTEGER CHECK (>=0),
    gravite_max INTEGER CHECK (1-4),             -- 1=Indemne, 2=LÃ©ger, 3=HospitalisÃ©, 4=TuÃ©
    
    -- MÃ©tadonnÃ©es
    est_doublon BOOLEAN DEFAULT FALSE,
    source VARCHAR(50) DEFAULT 'data.gouv.fr',
    hash_md5 VARCHAR(32),
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- idx_accidents_date (date_accident) - pour rangÃ©es temporelles
- idx_accidents_annee (annee) - pour filtrages annuels
- idx_accidents_commune (id_com) - pour requÃªtes gÃ©ographiques
- idx_accidents_gravite (gravite_max) - pour analyses critÃ¨res
- idx_accidents_jour_semaine (jour_semaine) - pattern semaine/weekend
- idx_accidents_heure (heure) - patterns horaires
- idx_accidents_num_acc (num_acc) - clÃ© mÃ©tier
- idx_accidents_annee_mois (annee, mois) - composite pour temporel
- idx_accidents_date_gravite (date_accident, gravite_max) - composite

TRIGGERS:
- trg_update_accident_timestamp (UPDATE timestamp automatiquement)
- trg_detect_duplicates (Marquer doublons)

CLÃ‰S Ã‰TRANGÃˆRES:
- id_com â†’ communes.id_com (CASCADE)
```

#### 4. **caracteristiques** (Conditions)
```sql
CREATE TABLE caracteristiques (
    id_caract SERIAL PRIMARY KEY,
    id_accident INTEGER FK REFERENCES accidents (CASCADE),
    
    -- Conditions
    luminosite VARCHAR(50),                      -- 'jour', 'crÃ©puscule', 'nuit'
    agglomeration BOOLEAN,                       -- 1=Oui, 0=Non
    intersection BOOLEAN,                        -- 1=Ã€ intersection
    conditions_atmosphere VARCHAR(100),          -- 'normal', 'pluie', 'brouillard', ...
    
    -- Route
    type_route VARCHAR(50),
    surface_route VARCHAR(50),
    infrastructure VARCHAR(100),
    type_collision VARCHAR(50),
    
    completude_pct DECIMAL(5, 2),                -- % de complÃ©tude de donnÃ©es
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- idx_caract_accident (id_accident)

CLÃ‰S Ã‰TRANGÃˆRES:
- id_accident â†’ accidents.id_accident (CASCADE)
```

#### 5. **lieux** (GÃ©olocalisation PrÃ©cise)
```sql
CREATE TABLE lieux (
    id_lieu SERIAL PRIMARY KEY,
    id_accident INTEGER FK REFERENCES accidents (CASCADE),
    
    -- GÃ©olocalisation â­ INDEXÃ‰E pour heatmaps
    latitude DECIMAL(10, 8),
    longitude DECIMAL(10, 8),
    
    -- Descriptions
    type_route VARCHAR(50),
    surface_route VARCHAR(50),
    situation VARCHAR(100),
    infrastructure VARCHAR(100),
    est_metropole BOOLEAN DEFAULT TRUE,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- idx_lieux_accident (id_accident)
- idx_lieux_geom (latitude, longitude) - pour requÃªtes de proximitÃ©

CLÃ‰S Ã‰TRANGÃˆRES:
- id_accident â†’ accidents.id_accident (CASCADE)
```

#### 6. **usagers** (Personnes ImpliquÃ©es)
```sql
CREATE TABLE usagers (
    id_usager SERIAL PRIMARY KEY,
    id_accident INTEGER FK REFERENCES accidents (CASCADE),
    num_vehicule INTEGER,                        -- 1=conducteur, 2+ passagers
    num_occupant INTEGER,
    
    -- DÃ©mographie (INDEXÃ‰E pour analyses)
    date_naissance DATE,
    age INTEGER,                                 -- â­ IndexÃ©
    sexe VARCHAR(1),                             -- '1'=M, '2'=F, 'Unknown'
    
    -- SÃ©curitÃ©
    place_vehicule VARCHAR(50),
    equipement_securite VARCHAR(100),            -- 'ceinture', 'casque', ...
    
    -- GravitÃ© pour cet usager
    gravite INTEGER CHECK (1-4),                 -- 1=Indemne, 2=LÃ©ger, 3=HospitalisÃ©, 4=DÃ©cÃ©dÃ©
    
    -- Ã‰tat
    activite VARCHAR(50),                        -- 'travail', 'loisir', 'personnel', ...
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- idx_usagers_accident (id_accident)
- idx_usagers_age (age) - pour distributions par Ã¢ge
- idx_usagers_sexe (sexe) - pour analyses genre

CLÃ‰S Ã‰TRANGÃˆRES:
- id_accident â†’ accidents.id_accident (CASCADE)
```

#### 7. **vehicules** (DonnÃ©es VÃ©hicules)
```sql
CREATE TABLE vehicules (
    id_vehicule SERIAL PRIMARY KEY,
    id_accident INTEGER FK REFERENCES accidents (CASCADE),
    num_vehicule INTEGER,                        -- NumÃ©ro du vÃ©hicule dans accident
    
    -- CaractÃ©ristiques
    categorie_vehicule VARCHAR(50),              -- 'voiture', 'camion', 'moto', ...
    
    -- ManÅ“uvre
    sens_circulation VARCHAR(50),
    nombre_occupants INTEGER CHECK (>=0),
    type_manoeuvre VARCHAR(100),
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- idx_vehicules_accident (id_accident)
- idx_vehicules_categorie (categorie_vehicule) - pour analyses par type

CLÃ‰S Ã‰TRANGÃˆRES:
- id_accident â†’ accidents.id_accident (CASCADE)
```

#### 8. **score_danger_commune** (Cache Analytique)
```sql
CREATE TABLE score_danger_commune (
    id_score SERIAL PRIMARY KEY,
    id_com INTEGER FK REFERENCES communes (CASCADE),
    
    -- Compteurs
    nombre_accidents INTEGER DEFAULT 0,
    nombre_personnes_impliquees INTEGER DEFAULT 0,
    nombre_personnes_blessee INTEGER DEFAULT 0,
    nombre_personnes_tuees INTEGER DEFAULT 0,
    gravite_moyenne DECIMAL(5, 2),
    
    -- Score Composite (0-100)
    score_danger DECIMAL(5, 2),                  -- â­ IndexÃ© pour tri rapide
    score_frequence DECIMAL(5, 2),               -- 50% du score
    score_gravite DECIMAL(5, 2),                 -- 30% du score
    score_personnes DECIMAL(5, 2),               -- 20% du score
    
    -- CatÃ©gorisation
    categorie_risque VARCHAR(20),                -- 'TRÃˆS_Ã‰LEVÃ‰', 'Ã‰LEVÃ‰', 'MOYEN', 'FAIBLE'
    
    -- TemporalitÃ©
    date_calcul DATE,
    annee_reference INTEGER,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

INDEXES:
- idx_score_commune (id_com)
- idx_score_danger (score_danger) - pour tri efficace
- idx_score_categorie (categorie_risque) - pour filtres

CLÃ‰S Ã‰TRANGÃˆRES:
- id_com â†’ communes.id_com (CASCADE)

UTILISATION:
- Cache prÃ©-calculÃ© pour Ã©viter aggrÃ©gations coÃ»teuses
- RecalculÃ© par procÃ©dure stockÃ©e calculer_scores_danger()
- UtilisÃ© pour classement communes/dÃ©partements
```

---

## ðŸ” Vues Analytiques

### 1. **v_accidents_enrichis** (Jointure ComplÃ¨te)

```sql
VIEW: v_accidents_enrichis
â”œâ”€â”€ Accidents enrichis avec toutes les dimensions
â”œâ”€â”€ Colonnes: num_acc, date, lieu (commune, rÃ©gion, densitÃ©), 
â”‚             gravitÃ©, conditions (jour/heure), geolocalisation
â””â”€â”€ Usage: Base pour toutes les analyses ad-hoc

SELECT * FROM accidents_schema.v_accidents_enrichis
WHERE annee = 2022 
  AND jour_semaine IN (6, 7)  -- Weekends
  AND gravite_max >= 3        -- Accidents graves
ORDER BY gravite_max DESC;
```

### 2. **v_resume_communes** (AgrÃ©gations)

```sql
VIEW: v_resume_communes
â”œâ”€â”€ Une ligne par commune
â”œâ”€â”€ Colonnes: statistics (accidents, personnes, gravitÃ© moyenne, max)
â”‚            dÃ©mographie (population, densitÃ©)
â”œâ”€â”€ Usage: Dashboard, comparaisons communes
â””â”€â”€ Index implicite: nom_com, densitÃ©

SELECT * FROM accidents_schema.v_resume_communes
ORDER BY nombre_accidents DESC
LIMIT 50;
```

---

## ðŸ“Š ProcÃ©dures StockÃ©es

### **calculer_scores_danger()** (Recalcul des Scores)

```sql
-- Recalculer tous les scores par commune
SELECT * FROM accidents_schema.calculer_scores_danger();

-- RÃ©sultat: Nombre de scores calculÃ©s
-- Formule: score = (freq * 0.5) + (gravitÃ© * 0.3) + (personnes * 0.2)
```

---

## ðŸš€ Installation et Utilisation

### 1. **CrÃ©er le SchÃ©ma**

```bash
# Option 1: Via psql
psql -U postgres -d accidents_db -f src/database/schema.sql

# Option 2: Via Python
python src/database/load_postgresql.py --create-schema
```

### 2. **Charger les DonnÃ©es**

```bash
# Charger depuis CSV nettoyÃ©s (data/cleaned/)
python src/database/load_postgresql.py

# Avec truncate (reset DB)
python src/database/load_postgresql.py --force

# Sans mettre Ã  jour communes
python src/database/load_postgresql.py --skip-communes
```

**RÃ©sultat Attendu:**
```
âœ“ SchÃ©ma PostgreSQL crÃ©Ã© avec succÃ¨s!

Tables crÃ©Ã©es:
  - departements (rÃ©fÃ©rentiel)
  - communes (rÃ©fÃ©rentiel + donnÃ©es dÃ©mographiques)
  - accidents (table principale)
  - caracteristiques (conditions)
  - lieux (gÃ©olocalisation)
  - usagers (donnÃ©es personnes)
  - vehicules (donnÃ©es vÃ©hicules)
  - score_danger_commune (analytique)

Vues crÃ©Ã©es:
  - v_accidents_enrichis
  - v_resume_communes

STATISTIQUES CHARGEMENT:
  â€¢ Communes: 12,234
  â€¢ Accidents: 68,432
  â€¢ CaractÃ©ristiques: 68,432
  â€¢ Lieux: 68,432
  â€¢ Usagers: 245,123
  â€¢ VÃ©hicules: 89,321
```

### 3. **Utiliser les RequÃªtes**

```python
from src.database.database_utils import DatabaseManager

db = DatabaseManager()

# Accidents graves (2022)
df = db.query_accidents(annee=2022, gravite_min=3)

# Communes les plus dangereuses
df = db.get_stats_communes(limit=20)

# Scores de danger
df = db.get_danger_scores(limit=50)

# Heatmap data
df = db.get_heatmap_data(annee=2023)

# Statistiques temporelles
df = db.get_stats_temporelles(annee=2022)

# Usagers par Ã¢ge
df = db.get_stats_usagers()

# Rapport qualitÃ©
print(db.generate_data_report())

db.close_pool()
```

---

## ðŸ“ˆ Cas d'Usage Analytiques

### 1. **Analyse de Risque par RÃ©gion**

```python
# Top 10 communes les plus dangereuses en ÃŽle-de-France
df = db.query_accidents(dep='75')
df_stats = df.groupby('nom_com').agg({
    'nombre_personnes': 'sum',
    'gravite_max': ['mean', 'max']
}).sort_values(by='nombre_personnes', ascending=False).head(10)
```

### 2. **Patterns Temporels (Heures de Pointe)**

```python
# Accidents par heure
df = db.get_stats_temporelles(annee=2022)
df_heure = df[df['heure'].isin([7, 8, 9, 17, 18, 19])]
df_heure.groupby('heure')['nombre_accidents'].sum().plot()
```

### 3. **Analyse DÃ©mographique (Ã‚ge, Genre)**

```python
# Taux de mortalitÃ© par tranche d'Ã¢ge
df = db.get_stats_usagers()
df['tranche_age'] = pd.cut(df['age'], bins=[0, 25, 45, 65, 100])
df.groupby('tranche_age').apply(lambda x: x['nombre_deces'] / x['nombre_usagers'] * 100)
```

### 4. **Scoring Communes pour Assurance**

```python
# Top 10 communes Ã  risque trÃ¨s Ã©levÃ©
df = db.get_danger_scores(limit=100)
df_tres_eleve = df[df['categorie_risque'] == 'TRÃˆS_Ã‰LEVÃ‰']

# ParamÃ¨tres de tarification
df_tres_eleve[['nom_com', 'score_danger', 'nombre_accidents', 
                'nombre_personnes_tuees', 'population']]
```

### 5. **ProximitÃ© GÃ©ographique (RequÃªte Spatiale)**

```python
# Accidents Ã  proximitÃ© (5km) d'une adresse
df = db.get_accidents_near(latitude=48.8566, longitude=2.3522, distance_km=5)
# Retourne accidents avec distance_km calculÃ©e
```

---

## ðŸ”’ SÃ©curitÃ© et Permissions

```sql
-- Permissions par dÃ©faut (PUBLIC peut READ)
GRANT USAGE ON SCHEMA accidents_schema TO PUBLIC;
GRANT SELECT ON ALL TABLES IN SCHEMA accidents_schema TO PUBLIC;
GRANT SELECT ON ALL VIEWS IN SCHEMA accidents_schema TO PUBLIC;

-- Pour l'application (INSERT/UPDATE):
-- CrÃ©er rÃ´le application avec permissions UPDATE seulement
CREATE ROLE app_user;
GRANT UPDATE ON accidents_schema.* TO app_user;
```

---

## ðŸ“Š Performances Attendues

| RequÃªte | Temps | Rows |
|---------|-------|------|
| SELECT * FROM accidents (limit 1000) | 50ms | 1000 |
| Stats communes (group by) | 200ms | 250 |
| Heatmap data (10k points) | 150ms | 10k |
| RequÃªte proximitÃ© (5km) | 100ms | Variable |
| Danger scores (top 50) | 75ms | 50 |

**Optimisations:**
- Indexes composites sur (annee, mois), (date_accident, gravite_max)
- Cache danger_scores (prÃ©-calculÃ©)
- Vues materialisÃ©es (optionnel, Phase 4)

---

## ðŸ“ Prochaines Ã‰tapes (Phase 4)

1. **API FastAPI** : Endpoints REST sur requÃªtes ci-dessus
2. **MatÃ©rialisation Vues** : Pour trÃ¨s grandes analyses
3. **Partitioning** : Partitionner par annÃ©e si > 500M rows
4. **RÃ©plication** : Backup/Failover PostgreSQL

---

## ðŸ“š Fichiers LivÃ©rÃ©s

- `src/database/schema.sql` (544 lignes) - DDL complet
- `src/database/load_postgresql.py` (650 lignes) - Chargeur
- `src/database/database_utils.py` (550 lignes) - RequÃªtes
- `docs/DATABASE_SCHEMA.md` (CE FICHIER) - Documentation

**Total Phase 3: 1,700+ lignes de code + documentation**
