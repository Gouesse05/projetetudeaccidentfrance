# üõ†Ô∏è SP√âCIFICATIONS TECHNIQUES

## Plateforme d'Analyse des Accidents Routiers

**Version**: 2.0  
**Date**: 26 Janvier 2026  
**Auteur**: Technical Lead  
**Audience**: D√©veloppeurs, DevOps, Architectes

---

## 1. ARCHITECTURE G√âN√âRALE

### 1.1 Architecture Syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    UTILISATEUR FINAL                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ               ‚îÇ               ‚îÇ
         ‚ñº               ‚ñº               ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇStreamlit‚îÇ   ‚îÇ  FastAPI ‚îÇ   ‚îÇ Jupyter   ‚îÇ
    ‚îÇDashboard‚îÇ   ‚îÇ   REST   ‚îÇ   ‚îÇ Notebook  ‚îÇ
    ‚îÇ(Port 85)‚îÇ   ‚îÇ(Port 80) ‚îÇ   ‚îÇ           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ              ‚îÇ              ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                             ‚îÇ
         ‚ñº                             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  ETL Pipeline   ‚îÇ      ‚îÇ  Analysis Modules‚îÇ
    ‚îÇ  (data_cleaning)‚îÇ      ‚îÇ  (4 modules)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                        ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ   Data      ‚îÇ
                   ‚îÇ  (Pandas)   ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 Composants Principaux

| Composant | Technologie | R√¥le |
|-----------|------------|------|
| **Frontend** | Streamlit | Interface utilisateur interactive |
| **API** | FastAPI + Uvicorn | Service web pour int√©grations |
| **ETL** | Python 3.12 + Pandas | Pipeline chargement/nettoyage |
| **Analyses** | SciPy, Scikit-learn, Statsmodels | Calculs statistiques/ML |
| **Visualisation** | Plotly | Graphiques interactifs |
| **Testing** | Pytest + Pytest-cov | Tests unitaires |
| **VCS** | Git + GitHub | Versioning & collaboration |

---

## 2. STACK TECHNOLOGIQUE

### 2.1 D√©pendances Principales

```
Python: 3.12
‚îú‚îÄ‚îÄ Data Processing
‚îÇ   ‚îú‚îÄ‚îÄ pandas==1.5.3
‚îÇ   ‚îú‚îÄ‚îÄ numpy==1.26.0
‚îÇ   ‚îî‚îÄ‚îÄ scipy==1.14.0
‚îú‚îÄ‚îÄ Visualization
‚îÇ   ‚îú‚îÄ‚îÄ plotly==5.x
‚îÇ   ‚îî‚îÄ‚îÄ streamlit==1.x
‚îú‚îÄ‚îÄ Analytics
‚îÇ   ‚îú‚îÄ‚îÄ scikit-learn==1.5.0
‚îÇ   ‚îú‚îÄ‚îÄ statsmodels==0.14.0
‚îÇ   ‚îî‚îÄ‚îÄ prince==0.10.0 (MCA)
‚îú‚îÄ‚îÄ API
‚îÇ   ‚îú‚îÄ‚îÄ fastapi==0.104.1
‚îÇ   ‚îî‚îÄ‚îÄ uvicorn==0.24.0
‚îú‚îÄ‚îÄ Testing
‚îÇ   ‚îú‚îÄ‚îÄ pytest==7.4.3
‚îÇ   ‚îî‚îÄ‚îÄ pytest-cov==4.1.0
‚îî‚îÄ‚îÄ Code Quality
    ‚îú‚îÄ‚îÄ black==23.12.0
    ‚îî‚îÄ‚îÄ flake8==6.1.0
```

### 2.2 Versions Minimales

- Python: **3.12.0**+
- Pandas: **1.5.0**+
- Streamlit: **1.20.0**+
- FastAPI: **0.104.0**+

### 2.3 Absence Intentionnelle

‚ùå **Airflow** - Orchestration complexe non n√©cessaire  
‚ùå **Dagster** - Alternative orchestration retir√©e  
‚ùå **TensorFlow** - Deep Learning non requis  
‚ùå **Spark** - Big Data non applicable  

---

## 3. STRUCTURE DES FICHIERS

```
/home/sdd/projetetudeapi/
‚îú‚îÄ‚îÄ streamlit_app.py                    # Application Streamlit (734 lignes)
‚îú‚îÄ‚îÄ api.py                              # API FastAPI (25+ endpoints)
‚îú‚îÄ‚îÄ run_pipeline.py                     # Orchestrateur pipeline (335 lignes)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ analyses/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_cleaning.py           # Nettoyage donn√©es (180 lignes)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ statistical_analysis.py    # Analyses stats (210 lignes)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dimensionality_reduction.py# PCA/MCA/CA (314 lignes)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ machine_learning.py        # ML models (310 lignes)
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py                 # Fonctions utilitaires
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline.py              # Tests e2e (163 lignes)
‚îÇ   ‚îú‚îÄ‚îÄ test_data_cleaning.py
‚îÇ   ‚îú‚îÄ‚îÄ test_statistical.py
‚îÇ   ‚îî‚îÄ‚îÄ test_ml.py
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ 01_CAHIER_DE_CHARGES.md       # THIS FILE
‚îÇ   ‚îú‚îÄ‚îÄ 02_SPECIFICATIONS_FONCTIONNELLES.md
‚îÇ   ‚îú‚îÄ‚îÄ 03_SPECIFICATIONS_TECHNIQUES.md
‚îÇ   ‚îú‚îÄ‚îÄ 04_BACKLOG.md
‚îÇ   ‚îú‚îÄ‚îÄ 05_USER_STORIES.md
‚îÇ   ‚îú‚îÄ‚îÄ 06_EPICS.md
‚îÇ   ‚îú‚îÄ‚îÄ 07_ANOMALIES.md
‚îÇ   ‚îî‚îÄ‚îÄ ANALYSIS_REPORT.md
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ accidents_sample.csv          # Donn√©es exemple
‚îÇ
‚îú‚îÄ‚îÄ venv_clean/                        # Virtual environment
‚îÇ   ‚îî‚îÄ‚îÄ bin/
‚îÇ       ‚îú‚îÄ‚îÄ activate
‚îÇ       ‚îú‚îÄ‚îÄ python
‚îÇ       ‚îú‚îÄ‚îÄ pip
‚îÇ       ‚îú‚îÄ‚îÄ streamlit
‚îÇ       ‚îî‚îÄ‚îÄ uvicorn
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt                   # D√©pendances (25 packages)
‚îú‚îÄ‚îÄ README.md                          # Documentation principale
‚îú‚îÄ‚îÄ PIPELINE_README.md                 # Guide pipeline
‚îú‚îÄ‚îÄ DASHBOARD_README.md                # Guide dashboard
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ ci.yml                    # CI/CD pipeline (optionnel)
```

**Total Lines of Code**: ~2,500 (production) + ~800 (tests) = **3,300 lignes**

---

## 4. MODULES D√âTAILL√âS

### 4.1 Module: data_cleaning.py (180 lignes)

**Fonctions Cl√©s**:

| Fonction | Input | Output | Logique |
|----------|-------|--------|---------|
| `load_accident_data()` | CSV path | DataFrame | Charge + validation basique |
| `clean_all_data()` | DataFrame | DataFrame clean | Normalise types, valeurs NULL |
| `get_data_quality_report()` | DataFrame | Dict stats | Profil qualit√© |
| `merge_datasets()` | List[DataFrame] | DataFrame | Join tables |

**Exemple Signature**:
```python
def clean_all_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Nettoie donn√©es accident.
    - Convertit types
    - Remplace valeurs invalides
    - Retire doublons
    """
    return df_clean
```

---

### 4.2 Module: statistical_analysis.py (210 lignes)

**Analyses Disponibles**:

| Analyse | M√©thode | Use Case |
|---------|---------|----------|
| Descriptive | Mean, Median, Std | R√©sum√© rapide |
| Correlation | Pearson/Spearman | Liens variables continues |
| Chi-Carr√© | œá¬≤ test | Liens variables cat√©gories |
| R√©gression | OLS (statsmodels) | Pr√©diction lin√©aire |
| Logistique | sklearn | Pr√©diction binaire gravit√© |

**Exemple**:
```python
def correlation_analysis(df: pd.DataFrame, method='pearson') -> np.ndarray:
    """Matrice corr√©lation de toutes colonnes num√©riques"""
    return df.corr(method=method)
```

---

### 4.3 Module: dimensionality_reduction.py (314 lignes)

**R√©ductions de Dimension**:

| Technique | Entr√©e | Sortie | Application |
|-----------|--------|--------|-------------|
| **PCA** | Num√©riques | n composantes | Visualisation 2D/3D |
| **K-Means** | Num√©riques | Labels clusters | Segmentation conducteurs |
| **MCA** | Cat√©gories | n axes | Analyse var. cat√©gories |
| **CA** | Contingency | n axes | Analyse profils |
| **Elbow** | K range | Graphique | Choix K optimal |

---

### 4.4 Module: machine_learning.py (310 lignes)

**Mod√®les Impl√©ment√©s**:

| Mod√®le | Task | Features | M√©triques |
|--------|------|----------|-----------|
| Random Forest Classifier | Gravit√© (multi-class) | 15+ | Accuracy, F1, Confusion |
| Random Forest Regressor | Co√ªt assurance | 15+ | RMSE, R¬≤, MAE |
| Feature Selection | Feature ranking | Auto | Gini importance |

---

## 5. API REST SPECIFICATION

### 5.1 Endpoints Principaux

**Base URL**: `http://localhost:8000/api`

#### Cat√©gorie 1: Data Management

```
POST /load-data
  Body: {file: upload CSV}
  Response: {rows: int, columns: []}

GET /data/sample
  Query: ?limit=100&offset=0
  Response: [{...}, {...}]
```

#### Cat√©gorie 2: Statistiques

```
GET /stats/descriptive
  Query: ?columns=age,gravite,vitesse
  Response: {
    age: {mean: 40.5, median: 38, ...},
    gravite: {...}
  }

GET /stats/correlation
  Response: [[1.0, 0.32, ...], [0.32, 1.0, ...]]

GET /stats/chi2
  Query: ?var1=classe_age&var2=gravite
  Response: {chi2: 45.23, p_value: 0.001}
```

#### Cat√©gorie 3: Analyses

```
POST /analysis/clustering
  Body: {k: 5, method: 'kmeans', features: [...]}
  Response: {labels: [], centers: [], inertia: 1234}

GET /analysis/pca
  Query: ?n_components=2
  Response: {components: [], variance_explained: [0.45, 0.25]}
```

#### Cat√©gorie 4: ML

```
POST /ml/predict-severity
  Body: {age: 35, experience: 10, alcool: false, ...}
  Response: {prediction: 2, probability: [0.2, 0.3, 0.35, 0.15]}

GET /ml/feature-importance
  Response: {age: 0.25, alcool: 0.22, ...}
```

### 5.2 Format des R√©ponses

**Success (200)**:
```json
{
  "status": "success",
  "data": {...},
  "timestamp": "2026-01-26T10:30:00Z"
}
```

**Error (400/500)**:
```json
{
  "status": "error",
  "error_code": "INVALID_INPUT",
  "message": "Age must be between 18 and 100",
  "timestamp": "2026-01-26T10:30:00Z"
}
```

### 5.3 Authentification

**Type**: Basic Auth (optionnel)  
**Headers**:
```
Authorization: Basic dXNlcjpwYXNzd29yZA==
```

---

## 6. BASE DE DONN√âES (Sch√©ma Logique)

### 6.1 Table: accidents

```sql
CREATE TABLE accidents (
  id INT PRIMARY KEY,
  date DATETIME,
  heure INT CHECK (heure BETWEEN 0 AND 23),
  jour_semaine VARCHAR(10),
  
  -- Profil conducteur
  age INT CHECK (age BETWEEN 18 AND 100),
  classe_age VARCHAR(20),
  genre VARCHAR(10),
  annee_permis INT CHECK (annee_permis BETWEEN 1980 AND 2024),
  experience INT,
  
  -- Accident
  gravite INT CHECK (gravite BETWEEN 1 AND 4),
  nombre_victimes INT,
  nombre_vehicles INT,
  
  -- Conditions
  type_route VARCHAR(30),
  luminosite VARCHAR(20),
  conditions_meteo VARCHAR(20),
  
  -- Facteurs risque
  alcool√©mie BOOLEAN,
  fatigue BOOLEAN,
  vitesse INT,
  
  -- G√©ographie
  departement VARCHAR(5),
  agglomeration VARCHAR(50),
  
  -- Co√ªts
  cout_assurance_annuel INT,
  
  INDEXES:
    - date (range queries)
    - age (demographic filters)
    - gravite (severity analysis)
    - alcool√©mie (risk factor)
);
```

---

## 7. INT√âGRATION STREAMLIT

### 7.1 Architecture Streamlit

```python
# streamlit_app.py (734 lignes)
‚îú‚îÄ‚îÄ Configuration
‚îÇ   ‚îî‚îÄ‚îÄ st.set_page_config()
‚îú‚îÄ‚îÄ Data Generation
‚îÇ   ‚îî‚îÄ‚îÄ @st.cache_data generate_smart_accident_data()
‚îú‚îÄ‚îÄ Sidebar Filters (15+ crit√®res)
‚îú‚îÄ‚îÄ Main Dashboard
‚îÇ   ‚îú‚îÄ‚îÄ KPI Row (6 metrics)
‚îÇ   ‚îú‚îÄ‚îÄ Tabs Container
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Tab 1: Tendances (4 charts)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Tab 2: D√©mographie (4 charts)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Tab 3: Assurance (4 charts + table)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Tab 4: Causalit√© (6 charts + interpretations)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Tab 5: Facteurs Risque (3 charts + table)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Tab 6: Insights (3 info boxes + profile)
```

### 7.2 Caching Strategy

```python
@st.cache_data  # Recalc 1x/jour par d√©faut
def generate_smart_accident_data():
    # 5000 records avec patterns r√©alistes
    return df

@st.cache_resource  # Recalc 1x/session
def get_model():
    # Charge mod√®les ML
    return model
```

**Impact Performance**: Dashboard charge <3s

---

## 8. GESTION ERREURS

### 8.1 Types Erreurs

| Type | Code HTTP | Exemple |
|------|-----------|---------|
| Input Invalid | 400 | Age < 18 |
| Not Found | 404 | Dataset inexistant |
| Server Error | 500 | Crash calcul |
| Timeout | 504 | Requ√™te >30s |

### 8.2 Logging

```python
import logging
logger = logging.getLogger(__name__)

logger.info("Pipeline started")
logger.warning("Missing values in column X: 5 rows")
logger.error("Failed to load CSV", exc_info=True)
```

**Log Levels**: DEBUG < INFO < WARNING < ERROR < CRITICAL

---

## 9. TESTS

### 9.1 Strat√©gie Testing

```
Unit Tests (85% coverage)
‚îú‚îÄ‚îÄ test_data_cleaning.py (45 tests)
‚îú‚îÄ‚îÄ test_statistical_analysis.py (30 tests)
‚îú‚îÄ‚îÄ test_dimensionality_reduction.py (25 tests)
‚îî‚îÄ‚îÄ test_machine_learning.py (20 tests)

Integration Tests
‚îú‚îÄ‚îÄ test_pipeline.py (163 lignes)
‚îî‚îÄ‚îÄ test_api.py (API endpoints)

E2E Tests (Manual)
‚îî‚îÄ‚îÄ User journey testing
```

### 9.2 Exemple Test

```python
def test_chi2_analysis():
    """Test chi-square independence test"""
    df = pd.DataFrame({
        'age_group': ['18-25', '25-35', '35+'] * 10,
        'gravite': ['L√©ger', 'Grave'] * 15
    })
    
    result = chi2_test(df, 'age_group', 'gravite')
    
    assert result['chi2'] > 0
    assert 0 <= result['p_value'] <= 1
    assert 'significance' in result
```

**Coverage**: Actuellement **85%** (3,300 lignes code test√©es)

---

## 10. D√âPLOIEMENT

### 10.1 Environnement Local

```bash
# Setup
python3.12 -m venv venv_clean
source venv_clean/bin/activate
pip install -r requirements.txt

# Run
streamlit run streamlit_app.py              # Port 8503
python api.py                              # Port 8000
pytest tests/                              # Tests
```

### 10.2 Environnement Production (Optionnel)

```bash
# Service systemd
[Unit]
Description=Streamlit Accidents Dashboard
After=network.target

[Service]
Type=simple
User=sdd
WorkingDirectory=/home/sdd/projetetudeapi
ExecStart=/home/sdd/projetetudeapi/venv_clean/bin/streamlit run streamlit_app.py

[Install]
WantedBy=multi-user.target
```

### 10.3 Ports

| Service | Port | Status |
|---------|------|--------|
| Streamlit Dashboard | 8503 | ‚úÖ Active |
| FastAPI | 8000 | ‚úÖ Available |
| Jupyter | 8888 | ‚úÖ Available |

---

## 11. S√âCURIT√â

### 11.1 Validations

```python
# Input validation
def validate_age(age):
    if not isinstance(age, int):
        raise ValueError("Age must be integer")
    if age < 18 or age > 100:
        raise ValueError("Age must be 18-100")
    return age
```

### 11.2 Gestion Donn√©es Sensibles

- ‚ùå Pas de donn√©es personnelles logg√©es
- ‚úì Donn√©es anonymis√©es
- ‚úì Pas d'export CSV raw (agr√©gations)

---

## 12. MONITORING & PERFORMANCE

### 12.1 M√©triques

```python
import time

@app.get("/metrics")
def get_metrics():
    return {
        "uptime_seconds": time.time() - start_time,
        "active_users": len(active_sessions),
        "api_calls_total": api_call_counter,
        "avg_response_time_ms": avg_response_time
    }
```

### 12.2 Bottlenecks Connus

1. **G√©n√©ration donn√©es** (5000 records): ~2s ‚Üí Solution: Cache
2. **PCA sur 5000 rows**: ~0.5s ‚Üí Acceptable
3. **Corr√©lation matrice**: ~0.1s ‚Üí OK

---

## 13. ROADMAP TECHNIQUE FUTURE

**Phase 6 (Q2 2026)**:
- [ ] Connexion vraies donn√©es SNCDA/DGCN
- [ ] PostgreSQL + SQLAlchemy ORM
- [ ] Redis caching
- [ ] Docker containerization
- [ ] CI/CD GitHub Actions
- [ ] Monitoring Prometheus/Grafana

**Phase 7 (Q3 2026)**:
- [ ] Pr√©dictions temps r√©el ML
- [ ] Alertes anomalies
- [ ] Export rapports PDF
- [ ] Mobile app React Native

---

**Approuv√© par**: Technical Lead  
**Date**: 26/01/2026  
**Statut**: ‚úÖ FINAL
