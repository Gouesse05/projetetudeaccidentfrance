"""
Streamlit Dashboard - Accidents Routiers Analysis
Interactive visualization of accident data and analyses
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys
import json

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from analyses.data_cleaning import load_accident_data, clean_all_data, get_data_quality_report
from analyses.statistical_analysis import (
    correlation_analysis, descriptive_statistics, chi2_test
)
from analyses.dimensionality_reduction import pca_analysis, kmeans_clustering
from analyses.machine_learning import train_random_forest_classifier, feature_selection

# Page config
st.set_page_config(
    page_title="Accidents Routiers Dashboard",
    page_icon="üöó",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main {
        padding: 0rem 0rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# SIDEBAR - Navigation and Controls
# ============================================================================
st.sidebar.title("üöó Accidents Routiers")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "Navigation",
    ["üè† Accueil", "üìä Donn√©es", "üìà Statistiques", "ü§ñ Machine Learning", "üîç Dimensionalit√©"]
)

st.sidebar.markdown("---")
st.sidebar.info(
    """
    **Phase 5 - Production Ready**
    
    - ‚úÖ 4 modules d'analyse
    - ‚úÖ 25+ endpoints API
    - ‚úÖ Pipeline manuel
    - ‚úÖ Zero conflicts
    """
)

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

@st.cache_data
def load_data():
    """Charger et nettoyer les donn√©es"""
    try:
        # Load sample data or create dummy data
        data = {
            'numeric_col1': np.random.randn(1000),
            'numeric_col2': np.random.randn(1000),
            'numeric_col3': np.random.randint(0, 100, 1000),
            'categorical_col': np.random.choice(['A', 'B', 'C'], 1000),
            'severity': np.random.choice([1, 2, 3], 1000),
            'month': np.random.randint(1, 13, 1000),
            'hour': np.random.randint(0, 24, 1000)
        }
        return pd.DataFrame(data)
    except Exception as e:
        st.error(f"Erreur chargement donn√©es: {e}")
        return None

# ============================================================================
# PAGE: ACCUEIL
# ============================================================================

if page == "üè† Accueil":
    st.title("üöó Dashboard Accidents Routiers")
    st.markdown("Analyse compl√®te des donn√©es d'accidents routiers en France")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="Modules",
            value="4",
            delta="Data, Stats, ML, Dim"
        )
    
    with col2:
        st.metric(
            label="Endpoints API",
            value="25+",
            delta="FastAPI"
        )
    
    with col3:
        st.metric(
            label="Packages",
            value="23",
            delta="Zero conflicts"
        )
    
    with col4:
        st.metric(
            label="Status",
            value="Ready",
            delta="Production"
        )
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìö Architecture")
        st.write("""
        **Pipeline d'analyse complet:**
        1. **Data Cleaning** - Nettoyage et normalisation
        2. **Statistical Analysis** - Analyses statistiques
        3. **Dimensionality Reduction** - PCA, K-Means
        4. **Machine Learning** - Random Forest, Feature Selection
        """)
    
    with col2:
        st.subheader("üöÄ D√©marrage")
        st.code("""
# Pipeline complet
python run_pipeline.py

# API
uvicorn src.api.main:app --reload

# Tests
pytest tests/ -v
        """, language="bash")

# ============================================================================
# PAGE: DONN√âES
# ============================================================================

elif page == "üìä Donn√©es":
    st.title("üìä Exploration des Donn√©es")
    
    df = load_data()
    
    if df is not None:
        st.subheader("Aper√ßu des donn√©es")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Lignes", len(df))
        with col2:
            st.metric("Colonnes", len(df.columns))
        with col3:
            st.metric("Valeurs manquantes", df.isnull().sum().sum())
        
        st.markdown("---")
        
        # Data sample
        st.subheader("Exemple de donn√©es")
        st.dataframe(df.head(10), use_container_width=True)
        
        st.markdown("---")
        
        # Statistics
        st.subheader("Statistiques descriptives")
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        stats_data = df[numeric_cols].describe().T
        st.dataframe(stats_data, use_container_width=True)
        
        st.markdown("---")
        
        # Distribution plots
        st.subheader("Distributions")
        col1, col2 = st.columns(2)
        
        with col1:
            fig = px.histogram(df, x='numeric_col1', nbins=30, title='Distribution Col1')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            fig = px.histogram(df, x='numeric_col2', nbins=30, title='Distribution Col2')
            st.plotly_chart(fig, use_container_width=True)

# ============================================================================
# PAGE: STATISTIQUES
# ============================================================================

elif page == "üìà Statistiques":
    st.title("üìà Analyses Statistiques")
    
    df = load_data()
    
    if df is not None:
        st.subheader("Corr√©lations")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        # Correlation matrix
        corr_matrix = df[numeric_cols].corr()
        
        fig = px.imshow(
            corr_matrix,
            labels=dict(color="Corr√©lation"),
            color_continuous_scale="RdBu_r",
            zmin=-1, zmax=1,
            aspect="auto",
            title="Matrice de Corr√©lation"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        # Descriptive stats by category
        st.subheader("Statistiques par Cat√©gorie")
        
        col1, col2 = st.columns([3, 1])
        
        with col2:
            selected_cat = st.selectbox(
                "Cat√©gorie",
                df.select_dtypes(include=['object']).columns.tolist() + ['severity']
            )
        
        with col1:
            if selected_cat in df.columns:
                stats_by_cat = df.groupby(selected_cat)[numeric_cols[0]].agg([
                    'count', 'mean', 'std', 'min', 'max'
                ]).round(2)
                st.dataframe(stats_by_cat, use_container_width=True)

# ============================================================================
# PAGE: MACHINE LEARNING
# ============================================================================

elif page == "ü§ñ Machine Learning":
    st.title("ü§ñ Machine Learning")
    
    df = load_data()
    
    if df is not None:
        st.subheader("Feature Importance")
        
        # Create target for ML
        df['target'] = (df['numeric_col1'] > 0).astype(int)
        feature_cols = ['numeric_col1', 'numeric_col2', 'numeric_col3']
        
        try:
            # Train model
            ml_result = train_random_forest_classifier(
                df,
                feature_cols=feature_cols,
                target_col='target',
                n_estimators=50
            )
            
            # Feature importance
            importance_df = pd.DataFrame(
                list(ml_result['feature_importance'].items()),
                columns=['Feature', 'Importance']
            ).sort_values('Importance', ascending=False)
            
            fig = px.bar(
                importance_df,
                x='Importance',
                y='Feature',
                orientation='h',
                title='Importance des Features',
                color='Importance',
                color_continuous_scale='Blues'
            )
            st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("---")
            
            # Metrics
            col1, col2, col3, col4 = st.columns(4)
            
            metrics = ml_result['metrics']
            with col1:
                st.metric("Accuracy", f"{metrics['accuracy']:.3f}")
            with col2:
                st.metric("Precision", f"{metrics['precision']:.3f}")
            with col3:
                st.metric("Recall", f"{metrics['recall']:.3f}")
            with col4:
                st.metric("F1 Score", f"{metrics['f1']:.3f}")
            
        except Exception as e:
            st.error(f"Erreur ML: {e}")

# ============================================================================
# PAGE: DIMENSIONALIT√â
# ============================================================================

elif page == "üîç Dimensionalit√©":
    st.title("üîç R√©duction de Dimensionalit√©")
    
    df = load_data()
    
    if df is not None:
        st.subheader("Analyse PCA")
        
        numeric_df = df.select_dtypes(include=[np.number])
        
        try:
            # PCA
            pca_result = pca_analysis(numeric_df, n_components=2)
            
            # K-Means
            kmeans_result = kmeans_clustering(numeric_df, n_clusters=3)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("PCA - Variance Expliqu√©e")
                if 'variance_explained' in pca_result:
                    var_df = pd.DataFrame({
                        'Component': [f'PC{i+1}' for i in range(len(pca_result['variance_explained']))],
                        'Variance': pca_result['variance_explained']
                    })
                    fig = px.bar(var_df, x='Component', y='Variance', title='Variance Expliqu√©e')
                    st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.subheader("K-Means Clustering")
                if 'inertia' in kmeans_result:
                    st.metric("Inertia", f"{kmeans_result['inertia']:.2f}")
                if 'silhouette_score' in kmeans_result:
                    st.metric("Silhouette Score", f"{kmeans_result['silhouette_score']:.3f}")
            
        except Exception as e:
            st.error(f"Erreur dimensionalit√©: {e}")

# ============================================================================
# Footer
# ============================================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #888;'>
    <small>Phase 5 - Production Ready | Built with Streamlit & Plotly</small>
</div>
""", unsafe_allow_html=True)
