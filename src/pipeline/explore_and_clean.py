"""
Exploration et nettoyage des donn√©es d'accidents routiers
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple
from datetime import datetime

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Chemins
BASE_DIR = Path(__file__).parent.parent.parent
RAW_DATA_DIR = BASE_DIR / "data" / "raw"
CLEAN_DATA_DIR = BASE_DIR / "data" / "clean"


def ensure_clean_data_dir():
    """Cr√©e le r√©pertoire des donn√©es nettoy√©es"""
    CLEAN_DATA_DIR.mkdir(parents=True, exist_ok=True)


def explore_csv(file_path: Path) -> Dict:
    """
    Explore un fichier CSV et retourne des statistiques
    
    Args:
        file_path: Chemin du fichier CSV
    
    Returns:
        Dict avec infos sur le fichier
    """
    try:
        logger.info(f"\nüìÇ Exploration: {file_path.name}")
        logger.info("-" * 60)
        
        df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)
        
        info = {
            "filename": file_path.name,
            "rows": len(df),
            "columns": len(df.columns),
            "size_mb": file_path.stat().st_size / (1024 * 1024),
            "columns_list": df.columns.tolist(),
            "dtypes": df.dtypes.to_dict(),
            "missing": df.isnull().sum().to_dict(),
            "duplicates": len(df) - len(df.drop_duplicates()),
            "shape": df.shape
        }
        
        logger.info(f"  Lignes: {info['rows']:,}")
        logger.info(f"  Colonnes: {info['columns']}")
        logger.info(f"  Taille: {info['size_mb']:.2f} MB")
        logger.info(f"  Doublons: {info['duplicates']}")
        
        logger.info(f"\n  üìã Colonnes:")
        for col in df.columns:
            missing = df[col].isnull().sum()
            missing_pct = (missing / len(df)) * 100
            dtype = df[col].dtype
            logger.info(f"    - {col:30} | {str(dtype):15} | Missing: {missing:6} ({missing_pct:5.2f}%)")
        
        logger.info(f"\n  üìä Statistiques descriptives (num√©riques):")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            logger.info(df[numeric_cols].describe().to_string())
        
        logger.info(f"\n  üî§ Exemples de donn√©es (5 premi√®res lignes):")
        logger.info(df.head().to_string())
        
        return df, info
        
    except Exception as e:
        logger.error(f"‚úó Erreur lors de l'exploration: {e}")
        return None, None


def explore_all_datasets():
    """Explore tous les fichiers CSV dans le r√©pertoire raw"""
    
    ensure_clean_data_dir()
    
    logger.info("\n" + "=" * 80)
    logger.info("üîç EXPLORATION DONN√âES BRUTES")
    logger.info("=" * 80)
    
    csv_files = list(RAW_DATA_DIR.glob("*.csv"))
    
    if not csv_files:
        logger.warning("‚ö† Aucun fichier CSV trouv√© dans data/raw/")
        return {}
    
    exploration_results = {}
    
    for csv_file in csv_files:
        df, info = explore_csv(csv_file)
        if df is not None:
            exploration_results[csv_file.name] = {
                "dataframe": df,
                "info": info
            }
    
    return exploration_results


def clean_accidents_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Nettoie les donn√©es d'accidents
    
    Args:
        df: DataFrame brut
    
    Returns:
        DataFrame nettoy√©
    """
    logger.info("\nüßπ Nettoyage donn√©es accidents")
    logger.info("-" * 60)
    
    df = df.copy()
    initial_rows = len(df)
    
    # Supprimer les doublons complets
    df = df.drop_duplicates()
    logger.info(f"  Doublons supprim√©s: {initial_rows - len(df)}")
    
    # Supprimer les colonnes compl√®tement vides
    df = df.dropna(axis=1, how='all')
    logger.info(f"  Colonnes vides supprim√©es")
    
    # Normaliser les noms de colonnes
    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')
    logger.info(f"  Noms de colonnes normalis√©s")
    
    # G√©rer les valeurs manquantes
    for col in df.columns:
        if df[col].isnull().sum() > 0:
            missing_pct = (df[col].isnull().sum() / len(df)) * 100
            
            if missing_pct > 50:
                logger.warning(f"    {col}: {missing_pct:.1f}% manquant - suppression")
                df = df.drop(columns=[col])
            elif df[col].dtype == 'object':
                df[col] = df[col].fillna('UNKNOWN')
            elif df[col].dtype in ['int64', 'float64']:
                df[col] = df[col].fillna(df[col].median())
    
    logger.info(f"  Valeurs manquantes trait√©es")
    
    # Convertir les types de donn√©es
    date_cols = [col for col in df.columns if 'date' in col.lower() or 'jour' in col.lower()]
    for col in date_cols:
        try:
            df[col] = pd.to_datetime(df[col], errors='coerce')
            logger.info(f"  {col} converti en datetime")
        except Exception as e:
            logger.warning(f"  ‚ö† Erreur conversion {col}: {e}")
    
    # Supprimer les espaces des colonnes texte
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].str.strip()
    
    logger.info(f"‚úì Nettoyage termin√©: {len(df)} lignes")
    
    return df


def clean_caracteristiques_data(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoie les donn√©es de caract√©ristiques"""
    
    logger.info("\nüßπ Nettoyage donn√©es caract√©ristiques")
    logger.info("-" * 60)
    
    df = df.copy()
    
    # Normaliser noms colonnes
    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')
    
    # Supprimer doublons
    df = df.drop_duplicates()
    
    # G√©rer valeurs manquantes
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].fillna('UNKNOWN')
        else:
            df[col] = df[col].fillna(0)
    
    logger.info(f"‚úì Nettoyage termin√©: {len(df)} lignes")
    
    return df


def clean_lieux_data(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoie les donn√©es de lieux"""
    
    logger.info("\nüßπ Nettoyage donn√©es lieux")
    logger.info("-" * 60)
    
    df = df.copy()
    
    # Normaliser noms colonnes
    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')
    
    # Supprimer doublons
    df = df.drop_duplicates()
    
    # G√©rer coordonn√©es GPS (si pr√©sentes)
    geo_cols = [col for col in df.columns if 'lat' in col.lower() or 'lon' in col.lower()]
    for col in geo_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    logger.info(f"‚úì Nettoyage termin√©: {len(df)} lignes")
    
    return df


def clean_usagers_data(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoie les donn√©es d'usagers"""
    
    logger.info("\nüßπ Nettoyage donn√©es usagers")
    logger.info("-" * 60)
    
    df = df.copy()
    
    # Normaliser noms colonnes
    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')
    
    # Supprimer doublons
    df = df.drop_duplicates()
    
    logger.info(f"‚úì Nettoyage termin√©: {len(df)} lignes")
    
    return df


def clean_vehicules_data(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoie les donn√©es de v√©hicules"""
    
    logger.info("\nüßπ Nettoyage donn√©es v√©hicules")
    logger.info("-" * 60)
    
    df = df.copy()
    
    # Normaliser noms colonnes
    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')
    
    # Supprimer doublons
    df = df.drop_duplicates()
    
    logger.info(f"‚úì Nettoyage termin√©: {len(df)} lignes")
    
    return df


def save_clean_data(df: pd.DataFrame, filename: str):
    """Sauvegarde un DataFrame nettoy√© en CSV"""
    
    ensure_clean_data_dir()
    
    output_path = CLEAN_DATA_DIR / filename
    
    try:
        df.to_csv(output_path, index=False, encoding='utf-8')
        logger.info(f"‚úì Fichier sauvegard√©: {output_path.name}")
        return output_path
    except Exception as e:
        logger.error(f"‚úó Erreur sauvegarde: {e}")
        return None


def generate_quality_report(exploration_results: Dict) -> str:
    """
    G√©n√®re un rapport de qualit√© des donn√©es
    
    Args:
        exploration_results: R√©sultats de l'exploration
    
    Returns:
        Rapport format√©
    """
    
    report = "\n" + "=" * 80 + "\n"
    report += "üìä RAPPORT DE QUALIT√â DES DONN√âES\n"
    report += "=" * 80 + "\n"
    
    for filename, data in exploration_results.items():
        info = data['info']
        report += f"\nüìÅ {filename}\n"
        report += f"  Lignes: {info['rows']:,}\n"
        report += f"  Colonnes: {info['columns']}\n"
        report += f"  Taille: {info['size_mb']:.2f} MB\n"
        report += f"  Doublons: {info['duplicates']}\n"
        
        # Colonnes avec donn√©es manquantes
        missing_cols = {col: count for col, count in info['missing'].items() if count > 0}
        if missing_cols:
            report += f"  Donn√©es manquantes:\n"
            for col, count in missing_cols.items():
                pct = (count / info['rows']) * 100
                report += f"    - {col}: {count} ({pct:.1f}%)\n"
    
    report += "\n" + "=" * 80 + "\n"
    
    return report


def main():
    """Fonction principale"""
    
    logger.info("\n" + "=" * 80)
    logger.info("üîç EXPLORATION ET NETTOYAGE DONN√âES ACCIDENTS")
    logger.info("=" * 80)
    
    # √âtape 1: Explorer
    exploration_results = explore_all_datasets()
    
    if not exploration_results:
        logger.error("‚úó Aucune donn√©e √† explorer")
        return False
    
    # √âtape 2: Nettoyer et sauvegarder
    logger.info("\n" + "=" * 80)
    logger.info("üßπ NETTOYAGE DES DONN√âES")
    logger.info("=" * 80)
    
    cleaning_results = {}
    
    for filename, data in exploration_results.items():
        df = data['dataframe']
        
        # Appliquer le nettoyage appropri√© selon le type de fichier
        if 'accident' in filename.lower():
            cleaned_df = clean_accidents_data(df)
        elif 'caracteristique' in filename.lower():
            cleaned_df = clean_caracteristiques_data(df)
        elif 'lieu' in filename.lower():
            cleaned_df = clean_lieux_data(df)
        elif 'usager' in filename.lower():
            cleaned_df = clean_usagers_data(df)
        elif 'vehicule' in filename.lower():
            cleaned_df = clean_vehicules_data(df)
        else:
            cleaned_df = clean_accidents_data(df)  # Nettoyage g√©n√©rique par d√©faut
        
        # Sauvegarder
        output_path = save_clean_data(cleaned_df, f"clean_{filename}")
        if output_path:
            cleaning_results[filename] = {
                "output": output_path,
                "rows": len(cleaned_df),
                "columns": len(cleaned_df.columns)
            }
    
    # √âtape 3: G√©n√©rer rapport
    logger.info(generate_quality_report(exploration_results))
    
    logger.info("\n" + "=" * 80)
    logger.info("‚úÖ NETTOYAGE TERMIN√â")
    logger.info("=" * 80)
    
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
