# ğŸš— Pipeline DonnÃ©es Accidents Routiers

Pipeline ETL complet pour ingestion, exploration et nettoyage des donnÃ©es d'accidents routiers France.

## ğŸ“‹ Contenu

- `download_data.py` - TÃ©lÃ©chargement automatique avec vÃ©rification de hash
- `explore_and_clean.py` - Exploration et nettoyage des donnÃ©es
- `explore_datasources.py` - Script d'exploration des sources data.gouv.fr
- `data_config.py` - Configuration centralisÃ©e des datasets
- `run_pipeline.py` - Orchestration du pipeline ETL complet

## ğŸš€ Utilisation rapide

### 1. Explorer les sources de donnÃ©es

```bash
python explore_datasources.py
```

Affiche les datasets disponibles sur data.gouv.fr et leurs ressources.

### 2. TÃ©lÃ©charger les donnÃ©es

```bash
# TÃ©lÃ©chargement normal
python download_data.py

# Forcer le re-tÃ©lÃ©chargement
python download_data.py --force

# Afficher les URLs et explorer
python explore_datasources.py
```

**RÃ©sultat**: Fichiers tÃ©lÃ©chargÃ©s dans `data/raw/` avec mÃ©tadonnÃ©es en `.metadata.json`

### 3. Explorer et nettoyer

```bash
python explore_and_clean.py
```

Affiche les statistiques des donnÃ©es brutes et gÃ©nÃ¨re les fichiers nettoyÃ©s dans `data/clean/`

### 4. Pipeline complet

```bash
# Pipeline complet
python run_pipeline.py

# Avec options
python run_pipeline.py --force-download
python run_pipeline.py --skip-download  # Sauter tÃ©lÃ©chargement
```

## ğŸ“Š Flux du pipeline

```
data.gouv.fr
     â†“
download_data.py (tÃ©lÃ©charge + vÃ©rif hash)
     â†“
data/raw/*.csv
     â†“
explore_and_clean.py (exploration + nettoyage)
     â†“
data/clean/*.csv
     â†“
(prÃªt pour PostgreSQL)
```

## ğŸ”§ Configuration

Ã‰diter `data_config.py` pour:
- Ajouter/modifier les URLs des datasets
- Configurer le nettoyage (colonnes Ã  garder, traitement valeurs manquantes)
- DÃ©finir les validations
- Configurer l'import PostgreSQL

## ğŸ“ FonctionnalitÃ©s

### `download_data.py`

âœ… TÃ©lÃ©chargement depuis data.gouv.fr
âœ… VÃ©rification de hash MD5
âœ… DÃ©tection des changements
âœ… MÃ©tadonnÃ©es de tracking
âœ… Gestion des erreurs rÃ©seau
âœ… Barre de progression

**MÃ©tadonnÃ©es sauvegardÃ©es**:
- Hash du fichier (MD5)
- Hash distant
- Date de tÃ©lÃ©chargement
- Taille du fichier
- URL de source

### `explore_and_clean.py`

âœ… Exploration complÃ¨te des CSV
âœ… Statistiques descriptives
âœ… DÃ©tection des valeurs manquantes
âœ… Suppression des doublons
âœ… Normalisation des noms de colonnes
âœ… Conversion des types de donnÃ©es
âœ… Rapport de qualitÃ©

**Nettoyages appliquÃ©s**:
- Supprimer les doublons
- Supprimer les colonnes vides
- Normaliser les noms (minuscules, underscores)
- GÃ©rer les valeurs manquantes
- Convertir les dates
- Convertir les numÃ©riques
- Supprimer les espaces inutiles

### `explore_datasources.py`

âœ… Exploration de l'API data.gouv.fr
âœ… Lister les datasets de SÃ©curitÃ© RoutiÃ¨re
âœ… RÃ©cupÃ©rer les URLs de ressources
âœ… Informations de mise Ã  jour

## ğŸ“‚ Structure des donnÃ©es

### Raw (avant nettoyage)

```
data/raw/
â”œâ”€â”€ accidents.csv          # DonnÃ©es d'accidents
â”œâ”€â”€ caracteristiques.csv   # CaractÃ©ristiques des accidents
â”œâ”€â”€ lieux.csv             # Lieux (coordonnÃ©es, routes)
â”œâ”€â”€ usagers.csv           # DonnÃ©es des usagers
â”œâ”€â”€ vehicules.csv         # DonnÃ©es des vÃ©hicules
â””â”€â”€ .metadata.json        # MÃ©tadonnÃ©es de tÃ©lÃ©chargement
```

### Clean (aprÃ¨s nettoyage)

```
data/clean/
â”œâ”€â”€ clean_accidents.csv
â”œâ”€â”€ clean_caracteristiques.csv
â”œâ”€â”€ clean_lieux.csv
â”œâ”€â”€ clean_usagers.csv
â””â”€â”€ clean_vehicules.csv
```

## ğŸ”‘ Colonnes principales

### accidents
- `Num_Acc` - NumÃ©ro d'accident (clÃ© primaire)
- `Date` - Date de l'accident
- `an`, `mois`, `jour` - DÃ©composition temporelle
- `hrmn` - Heure et minute
- `dep` - Code dÃ©partement
- `com` - Code commune
- `grav` - GravitÃ© de l'accident
- `nbv` - Nombre de vÃ©hicules

### caracteristiques
- `Num_Acc` - RÃ©fÃ©rence accident
- `mois` - Mois
- `jour` - Jour
- `lumnos` - LuminositÃ©
- `agglo` - AgglomÃ©ration
- `int` - Intersection
- `atm` - Conditions atmosphÃ©riques
- `col` - Type de collision

### lieux
- `Num_Acc` - RÃ©fÃ©rence accident
- `route` - Type de route
- `Latitude` - CoordonnÃ©e latitude
- `Longitude` - CoordonnÃ©e longitude
- `surf` - Surface de la route
- `infra` - Type d'infrastructure
- `situ` - Situation de l'accident

### usagers
- `Num_Acc` - RÃ©fÃ©rence accident
- `Num_Veh` - NumÃ©ro vÃ©hicule
- `num_occupant` - NumÃ©ro occupant
- `Date_naiss` - Date de naissance
- `sexe` - Sexe
- `place` - Place dans le vÃ©hicule
- `actp` - ActivitÃ©
- `secu` - Ã‰quipement de sÃ©curitÃ©
- `grav` - GravitÃ© des blessures

### vehicules
- `Num_Acc` - RÃ©fÃ©rence accident
- `Num_Veh` - NumÃ©ro vÃ©hicule
- `senc` - Sens de circulation
- `catv` - CatÃ©gorie vÃ©hicule
- `occus` - Nombre occupants

## ğŸ“Š Exemple de rapport de qualitÃ©

```
ğŸ“Š RAPPORT DE QUALITÃ‰ DES DONNÃ‰ES

ğŸ“ accidents.csv
  Lignes: 1,234,567
  Colonnes: 28
  Taille: 245.50 MB
  Doublons: 1,234
  DonnÃ©es manquantes:
    - grav: 5,234 (0.4%)
    - agg: 12,345 (1.0%)
    - atm: 2,345 (0.2%)
```

## ğŸ› ï¸ Logs

Les logs sont Ã©crits dans:
- `pipeline.log` - Fichier de log
- Console - Affichage en temps rÃ©el

Niveau: INFO (tous les dÃ©tails)

## âš™ï¸ Requirements

```
pandas>=1.3.0
requests>=2.26.0
numpy>=1.21.0
psycopg2-binary>=2.9.0
python-dotenv>=0.19.0
```

## ğŸš¨ Troubleshooting

### Erreur de tÃ©lÃ©chargement
```
âœ— Erreur tÃ©lÃ©chargement: Connection timeout
```
â†’ VÃ©rifier la connexion rÃ©seau et les URLs

### Fichier non trouvÃ©
```
âš  Aucun fichier CSV trouvÃ© dans data/raw/
```
â†’ ExÃ©cuter d'abord `python download_data.py`

### Erreur d'encodage
```
âœ— Erreur lors de l'exploration: 'utf-8' codec can't decode
```
â†’ Modifier l'encodage dans `data_config.py`

## ğŸ“ˆ Prochaines Ã©tapes

1. âœ… TÃ©lÃ©chargement + nettoyage
2. â­ï¸ Import PostgreSQL
3. â­ï¸ API FastAPI
4. â­ï¸ Analyses et dashboards

## ğŸ“ Support

Voir le README principal: `../../README.md`
